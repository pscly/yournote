## [2026-01-23 21:53] - 任务：发布日记后台异步执行（前端刷新不影响）
- 原始需求：前端点击发布后，即使关闭页面/刷新，后台仍继续发布；前端仅负责触发与查看进度/结果。
- 实现目标/逻辑：
  - 后端新增“启动发布 Run”的接口：收到请求后在后台创建异步任务，按 run 的目标账号列表逐个发布并更新 `publish_diary_run_items.status`。
  - 任务幂等与防重：同一个 run 同时只能有一个后台任务运行；重复 start 请求应返回“已在运行”而不是启动第二份。
  - 进度可见：发布中将 item.status 写为 `running`，成功/失败写入 `success/failed`，错误信息落库，前端轮询即可看到进度变化。
- 核心变更：预计涉及 `backend/app/api/publish_diary.py`、`backend/app/services/background.py`、`backend/app/schemas/publish_diary.py`（状态枚举扩展）。
- 遗留/约束：保持现有表结构不做破坏性改动；尽量避免对 nideriji 的并发压力（后端并发需限制）。

## [2026-01-23 22:04] - 进展：已实现 run 后台发布与防重
- 原始需求：同上。
- 实现目标/逻辑：
  - 新增 `POST /publish-diaries/runs/{run_id}/start`：触发后台异步任务；同一 run 若已在运行则返回 `already_running=true` 防止重复启动。
  - 后台任务会把 `PublishDiaryRunItem.status` 置为 `running`（先提交），然后调用发布接口并落库 `success/failed` 与错误信息，前端轮询即可看到进度变化。
  - 并发限制：通过 `concurrency` 参数 + `asyncio.Semaphore` 控制并发（上限 10）。
- 核心变更：
  - `backend/app/services/background.py`：新增后台发布任务调度与执行（进程内任务表 `_publish_run_tasks`）。
  - `backend/app/api/publish_diary.py`：新增 start 接口并调用 `schedule_publish_run`。
  - `backend/app/schemas/publish_diary.py`：发布条目状态枚举扩展为包含 `running`，并新增 `PublishDiaryStartRunRequest`。
- 遗留/约束：
  - 后台任务为“进程内异步任务”，进程重启不会自动恢复；如需跨重启恢复，可后续增加“扫描未完成 run 并手动恢复/重试”能力。

## [2026-01-23 22:28] - 进展：修复 schemas 导出并完成启动级校验
- 原始需求：继续验证“后台发布不阻塞 + 可刷新继续”的链路，排查潜在运行期问题。
- 实现目标/逻辑：将 `PublishDiaryStartRunRequest` 纳入 `app.schemas` 的统一导出，避免运行期 ImportError；并用真实 import 验证启动链路。
- 核心变更：`backend/app/schemas/__init__.py`（补充 import 与 `__all__`）。
- 遗留/约束：可选优化点：当 force 重试导致状态从 success -> failed 时，是否需要清理旧的 `nideriji_diary_id/response_json` 以避免 UI 误读。

## [2026-01-25 11:12] - 任务：一次性同步本地 SQLite 到远程 PostgreSQL
- 原始需求：部署到服务器，远程用 PostgreSQL；本地继续 SQLite；需要把现有数据同步到远程一次。
- 实现目标/逻辑：
  - 使用现有 `backend/migrate_sqlite_to_postgres.py` 做一次性迁移：源库指向当前开发用的 SQLite（默认 `backend/yournote.db`），目标库通过 `DATABASE_URL` 指向远程 Postgres。
  - 迁移流程：目标库 `create_all` 建表 →（可选）清空目标业务表 → 按依赖顺序逐表拷贝 → 修复自增序列。
  - 安全：连接串密码不写入仓库；执行时通过环境变量或本机 `.env` 临时切换。
- 核心变更：待定（若调整脚本默认源库探测逻辑，将修改 `backend/migrate_sqlite_to_postgres.py`）。
- 遗留/约束：迁移前建议停止正在运行的后端，避免 SQLite 锁；目标库需已创建并保证用户有建表/写入权限。

## [2026-01-25 11:19] - 进展：已完成迁移并核对行数
- 原始需求：同上。
- 实现目标/逻辑：
  - 使用 `backend/migrate_db.py` 从 `backend/yournote.db` 全量迁移到远程 PostgreSQL（通过 `TARGET_DATABASE_URL`），并使用 `--reset-target` 先清空目标库以避免主键冲突。
  - 迁移后对关键表做 COUNT(*) 对账，源/目标行数一致。
  - 安全加固：`backend/migrate_db.py` 增加 `hide_parameters=True` 并在异常时仅输出 `orig`，避免报错把 token/密码等参数打印到控制台。
- 核心变更：`backend/migrate_db.py`（异常脱敏/隐藏参数）。
- 遗留/约束：若远程库需要保留已有数据，请不要使用 `--reset-target`，改为定制 upsert/合并策略。

## [2026-01-25 11:21] - 任务：Docker 化后端（FastAPI + SQLite 默认）
- 原始需求：为项目补齐 Dockerfile + docker-compose；不要引入 PostgreSQL 镜像；让服务器远端可直接部署与更新。
- 实现目标/逻辑：
  - 提供 `backend/Dockerfile`：基于 Python 3.13 + `uv.lock` 构建后端镜像，默认以 `python backend/run.py` 启动，并在 compose 中关闭 `BACKEND_RELOAD`。
  - 数据持久化：通过 volume 把 `./data` 挂载到容器 `/app/data`，并在 compose 中设置 `SQLITE_DB_PATH=./data/yournote.db`；同时挂载 `./logs` 以保留访问日志。
- 核心变更：`backend/Dockerfile`、`docker-compose.yml`（backend service、数据卷与关键环境变量）。
- 遗留/约束：如需切换到远程 PostgreSQL，仅配置 `DATABASE_URL`（本次不提供 pg 镜像）。

## [2026-02-04 23:50] - 任务：记录图片缓存（解析 `[图13]` 并返回稳定图片 URL）
- 原始需求：nideriji 的图片 URL 在浏览器展示为 `blob:`（不可复用）；希望后端缓存图片到本地（优先存数据库），前端查看记录时可直接访问本项目图片并展示附件。
- 实现目标/逻辑：
  - 新增图片缓存表 `cached_images`：按 `(nideriji_userid, image_id)` 唯一定位；存储 `content_type/data/sha256/fetch_status/fetched_at` 等元数据。
  - 新增图片接口 `GET /api/diaries/{diary_id}/images/{image_id}`：优先读缓存；缺失则用账号 `auth_token` 访问上游 `https://f.nideriji.cn/api/image/{userid}/{image_id}/` 拉取并缓存；支持 ETag/304 减少重复传输。
  - 记录详情返回 `attachments.images`：供前端把正文 `[图13]` 原位渲染为 `<img>`。
  - 同步后后台预拉取：仅对本次新增/更新且正文含图片占位符的记录触发；失败不影响同步成功。
- 核心变更：
  - `backend/app/models/cached_image.py`
  - `backend/app/services/image_cache.py`
  - `backend/app/api/diaries.py`（DiaryDetailResponse + attachments + images route）
  - `backend/app/services/collector.py`（sync 成功后 schedule 预拉取）
  - `backend/app/config.py`、仓库根 `.env.example`（新增图片缓存配置项）
- 遗留/约束：
  - 图片接口依赖 Cookie 门禁的同源访问；跨域需额外处理 cookie/cors。

## [2026-02-05 11:20] - 任务：新增配对记录统计支持“按天”（since/until 区间）
- 原始需求：前端希望查看“昨天/前天/某天”的新增配对记录明细，而当前接口只有 since_ms（无终点）。
- 实现目标/逻辑：
  - 为 `/stats/paired-diaries/increase` 增加可选参数 `until_ms`（UTC 毫秒时间戳）。
  - 过滤口径：`created_at >= since_dt AND created_at < until_dt`（左闭右开），以支持“按天”窗口的精确统计。
  - SQLite 兼容：延续现有做法，把 tz-aware 的 UTC datetime 转成 naive 再比较，避免 sqlite datetime 格式差异导致漏算/错算。
- 核心变更（计划）：`backend/app/api/stats.py`。
- 遗留/约束：保持对旧调用方兼容（不传 until_ms 时行为不变）。

## [2026-02-18 21:16] - 任务：新增 msg_count 增量事件表（统计用）
- 原始需求：新增“msg_count 增量事件表”SQLAlchemy 模型并注册到 models；启动时 `init_db()` 的 `Base.metadata.create_all()` 自动建表；字段/索引支持按 `recorded_at` 聚合、按 `(account_id, diary_id)` 分组汇总 delta。
- 实现目标/逻辑：
  - 新增事件表 `diary_msg_count_events`：存储 old/new/delta + recorded_at + source，并通过 FK 关联 account/diary（可选关联 sync_log）。
  - 索引策略：recorded_at 单列索引 + (account_id, diary_id, recorded_at) 复合索引，满足“时间窗口聚合 + 账号隔离分组”的常用查询。
  - 注册方式：在 `backend/app/models/__init__.py` 导入新模型，确保 `from . import models` 会把表注册进 `Base.metadata`。
- 核心变更：
  - `backend/app/models/diary_msg_count_event.py`
  - `backend/app/models/__init__.py`
- 遗留/约束：不引入 Alembic；仅新增表，不修改现有业务表结构；事件写入层面仍需业务代码保证只记录 delta>0。

## [2026-02-19 10:07] - 任务：同步写入 msg_count 增量事件 + stats 聚合接口 + unittest 回归
- 原始需求：显示并统计同步返回的 `diaries.msg_count`；当留言数增加时落库增量事件；提供“全库留言总数/窗口内增量合计与明细”的 stats 接口；补齐最小自动化回归。
- 实现目标/逻辑：
  - 同步：upsert 路径也更新已存在 Diary 的 `msg_count`；当 `msg_count` 增加时写入 `DiaryMsgCountEvent`（只记录 delta>0，按账号隔离）。
  - 统计：`/stats/overview` 返回 `total_msg_count=sum(Diary.msg_count)`；`/stats/msg-count/increase` 按时间窗口聚合 `sum(delta)` 并返回按 `(account_id, diary_id)` 分组的明细。
  - SQLite 兼容：datetime 比较沿用“tz-aware 转 naive UTC”策略，避免 sqlite datetime 格式差异导致漏算。
  - 测试：新增 unittest 覆盖 `total_delta` 不受 limit 影响、分组不串账号、排序与截断等关键口径。
- 核心变更：`backend/app/services/collector.py`、`backend/app/api/stats.py`、`backend/app/schemas/stats.py`、`backend/app/models/diary_msg_count_event.py`、`backend/tests/test_msg_count_increase.py`。
- 遗留/约束：不引入 Alembic；新表通过 `Base.metadata.create_all()` 创建。
